{"cells":[{"cell_type":"markdown","id":"d1415d69-f8dd-41c0-b927-ea54cdf392df","metadata":{"id":"d1415d69-f8dd-41c0-b927-ea54cdf392df"},"source":["# Face Recognition Attendance Project"]},{"cell_type":"markdown","id":"d2ece728-e2a6-4297-aaf0-d8789a0d8adc","metadata":{"id":"d2ece728-e2a6-4297-aaf0-d8789a0d8adc"},"source":["#### Import Necessary Dorectories"]},{"cell_type":"code","source":["!pip install face_recognition"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2utT0YeJKWM","executionInfo":{"status":"ok","timestamp":1651199432627,"user_tz":-330,"elapsed":33201,"user":{"displayName":"Prince Johnson","userId":"11501463855581254952"}},"outputId":"e3a73030-dd0c-4c21-b161-1bf8470826c1"},"id":"_2utT0YeJKWM","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Collecting face-recognition-models>=0.3.0\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[K     |████████████████████████████████| 100.1 MB 23 kB/s \n","\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.21.6)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566186 sha256=f37e692f2cfa7e2f6bd4e7a458a1341270ef15aab6007093da86b26531d0b790\n","  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"]}]},{"cell_type":"code","execution_count":null,"id":"77dbe149-7b43-4013-b03b-1732fdfbed02","metadata":{"id":"77dbe149-7b43-4013-b03b-1732fdfbed02"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import face_recognition\n","import os\n","from datetime import datetime"]},{"cell_type":"markdown","id":"ca33b23f-a321-42c8-a0a7-92d57504f89a","metadata":{"id":"ca33b23f-a321-42c8-a0a7-92d57504f89a"},"source":["#### Get Image Names as classnames for classification"]},{"cell_type":"code","execution_count":null,"id":"3958dad0-be03-4af1-aed5-7e29cd52426a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3958dad0-be03-4af1-aed5-7e29cd52426a","executionInfo":{"status":"ok","timestamp":1651199456443,"user_tz":-330,"elapsed":8037,"user":{"displayName":"Prince Johnson","userId":"11501463855581254952"}},"outputId":"3f773426-a653-4d0c-b5c1-e8a0984adc80"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Christo Baby.jpeg', 'Sudhanshu.jpg', 'Krish Naik.jpg', 'prince.jpg']\n","['Christo Baby', 'Sudhanshu', 'Krish Naik', 'prince']\n"]}],"source":["#path = '/home/punnoose1997/Documents/Ophir Projects/Face Attendance Project/Face-Recognition-Attendance-Projects-main/Training_images'\n","path = '/content/drive/MyDrive/Face Recognition Attendance Project/Training_images'\n","images = []\n","classNames = []\n","myList = os.listdir(path)\n","print(myList)\n","for cl in myList:\n","    curImg = cv2.imread(f'{path}/{cl}')\n","    images.append(curImg)\n","    classNames.append(os.path.splitext(cl)[0])\n","print(classNames)"]},{"cell_type":"markdown","id":"7d974a59-2a41-47b5-9cc3-5f7b455e2a8d","metadata":{"id":"7d974a59-2a41-47b5-9cc3-5f7b455e2a8d"},"source":["#### Function to Find face encodings from sample images"]},{"cell_type":"code","execution_count":null,"id":"de73751d-2f59-4c9a-a13a-3a1cd888e0d7","metadata":{"id":"de73751d-2f59-4c9a-a13a-3a1cd888e0d7"},"outputs":[],"source":["def findEncodings(images):\n","    encodeList = []\n","    \n","    for img in images:\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        encode = face_recognition.face_encodings(img)[0]\n","        encodeList.append(encode)\n","    return encodeList"]},{"cell_type":"markdown","id":"ddb35d9c-90e5-4eda-a63d-5d921011439f","metadata":{"id":"ddb35d9c-90e5-4eda-a63d-5d921011439f"},"source":["#### Function to Mark attendance of identified person on Attendance.csv file"]},{"cell_type":"code","execution_count":null,"id":"e9fc8eae-8519-45e4-9d80-0b3c3cb2e585","metadata":{"id":"e9fc8eae-8519-45e4-9d80-0b3c3cb2e585"},"outputs":[],"source":["def markAttendance(name):\n","    #with open('/home/punnoose1997/Documents/Ophir Projects/Face Attendance Project/Face-Recognition-Attendance-Projects-main/Attendance.csv', 'r+') as f:\n","    with open('/content/drive/MyDrive/Face Recognition Attendance Project/Attendance.csv', 'r+') as f:\n","        myDataList = f.readlines()\n","\n","\n","        nameList = []\n","        for line in myDataList:\n","            entry = line.split(',')\n","            nameList.append(entry[0])\n","            if name not in nameList:\n","                now = datetime.now()\n","                dtString = now.strftime('%H:%M:%S')\n","                f.writelines(f'\\n{name},{dtString}')"]},{"cell_type":"code","execution_count":null,"id":"6a135d45-457b-4f6e-a502-ec8825cf1882","metadata":{"id":"6a135d45-457b-4f6e-a502-ec8825cf1882"},"outputs":[],"source":["def markUnknown(name):\n","    #with open('/home/punnoose1997/Documents/Ophir Projects/Face Attendance Project/Face-Recognition-Attendance-Projects-main/UnknownList.csv', 'r+') as f:\n","    with open('/content/drive/MyDrive/Face Recognition Attendance Project/UnknownList.csv', 'r+') as f:\n","        myDataList = f.readlines()\n","\n","\n","        nameList = []\n","        for line in myDataList:\n","            entry = line.split(',')\n","            nameList.append(entry[0])\n","            if name not in nameList:\n","                now = datetime.now()\n","                dtString = now.strftime('%H:%M:%S')\n","                f.writelines(f'\\n{name},{dtString}')"]},{"cell_type":"code","source":["!pip3 install twilio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMOkynIWK6Ro","executionInfo":{"status":"ok","timestamp":1651199695238,"user_tz":-330,"elapsed":5383,"user":{"displayName":"Prince Johnson","userId":"11501463855581254952"}},"outputId":"b7b21a2a-e0d7-4115-9a16-f31b77be546d"},"id":"HMOkynIWK6Ro","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting twilio\n","  Downloading twilio-7.8.2-py2.py3-none-any.whl (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from twilio) (2.23.0)\n","Collecting PyJWT<3.0.0,>=2.0.0\n","  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from twilio) (2022.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (2021.10.8)\n","Installing collected packages: PyJWT, twilio\n","Successfully installed PyJWT-2.3.0 twilio-7.8.2\n"]}]},{"cell_type":"code","execution_count":null,"id":"342fed6f-16f2-47e2-a400-863b6284ff7c","metadata":{"id":"342fed6f-16f2-47e2-a400-863b6284ff7c"},"outputs":[],"source":["import os\n","from twilio.rest import Client\n","\n","def sendAlertTwilio(name):\n","    #This function sends alerts to specified Phone numbers\n","    account_sid = os.environ['AC4ae98176d5ff9b9eb257ea8c2503991b']\n","    auth_token = os.environ['b0c60ffc5b10ac8cd4fed2051ce37e65']\n","    target_number = '+918547999613'\n","    source_number = '+91 89438 42248'\n","    client = Client(account_sid, auth_token)\n","    message = client.messages.create(body=name+' has entered frame.', from_=source_number, to=target_number)\n","    print(message.sid)\n","    "]},{"cell_type":"markdown","id":"e5043222-31d1-40b8-9040-eaa593e77a01","metadata":{"id":"e5043222-31d1-40b8-9040-eaa593e77a01"},"source":["#### Find Encodings and print them.\n","#### Capture system webcam input"]},{"cell_type":"code","execution_count":null,"id":"a9e0f98d-4a17-42ed-9016-bf775e2ccfb8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a9e0f98d-4a17-42ed-9016-bf775e2ccfb8","executionInfo":{"status":"ok","timestamp":1651199724864,"user_tz":-330,"elapsed":10841,"user":{"displayName":"Prince Johnson","userId":"11501463855581254952"}},"outputId":"365e1443-7773-448d-96d5-f725ccea86be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding Complete\n"]}],"source":["encodeListKnown = findEncodings(images)\n","print('Encoding Complete')\n","\n","cap = cv2.VideoCapture(0)"]},{"cell_type":"markdown","id":"0b7ee0d5-69d4-4c6e-85d3-4599dce6788c","metadata":{"id":"0b7ee0d5-69d4-4c6e-85d3-4599dce6788c"},"source":["#### Process captured images, find face locations, encodings, compare faces, and add them to attendance"]},{"cell_type":"code","execution_count":null,"id":"60cf40b4-da0b-4cbe-b811-0fbbd33222e9","metadata":{"id":"60cf40b4-da0b-4cbe-b811-0fbbd33222e9","outputId":"9de537b2-3bc7-4bcd-9816-4ada0ec9cb4f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"]},{"ename":"error","evalue":"OpenCV(4.4.0) /tmp/pip-req-build-v1rk7obu/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34079/1495622888.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# img = captureScreen()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimgS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimgS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.4.0) /tmp/pip-req-build-v1rk7obu/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"]}],"source":["while True:\n","    success, img = cap.read()\n","# img = captureScreen()\n","    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n","    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n","\n","    facesCurFrame = face_recognition.face_locations(imgS)\n","    encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n","\n","    for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n","        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n","        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n","# print(faceDis)\n","        matchIndex = np.argmin(faceDis)\n","\n","        if matches[matchIndex]:\n","            name = classNames[matchIndex].upper()\n","# print(name)\n","            y1, x2, y2, x1 = faceLoc\n","            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n","            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n","            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n","            markAttendance(name)\n","        else:\n","            name = \"Unknown Person\"\n","            y1, x2, y2, x1 = faceLoc\n","            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n","            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n","            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n","            markUnknown(name)\n","            sendAlertTwilio(name)\n","            \n","\n","    cv2.imshow('Webcam', img)\n","    cv2.waitKey(1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"Face Recognition Attendance.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}